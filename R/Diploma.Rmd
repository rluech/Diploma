---
title: "Predicting Household Composition by TV Viewing Behavior"
subtitle: 'Diploma of Advanced Studies in Applied Statistics at ETH Zurich'
author: "Rafael LÃ¼chinger"
date: "`r format(Sys.time(), '%d %B %Y')`"
output: 
  pdf_document:
    fig_caption: yes
    keep_tex: yes
    number_sections: yes
    toc: yes
    toc_depth: 2
header-includes: \usepackage{float}
---

# Abstract

# Introduction 

TV audience in Switzerland is measured by [Mediapulse AG](https:://www.mediapulse.ch/en).
A representative [panel](https:://www.mediapulse.ch/en/tv/research-method/the-panel.html)
of roughly 2000 households is constantly under [measurement](https:://www.mediapulse.ch/en/tv/research-method/the-measuring-technique.html).
These homes were carefully selected by a complex sampling design and all 
household members have agreed to be part of the study. The TV viewing of each
household member is individually recorded and detailed demographics are known for 
each person. This allows the market to target TV audiences by relevant 
characteristics like age gender and many more.

One issue with the panel approach is poor granularity. That means sometimes 
the system can not provide any audience figures for a specific channel or airtime.
It is likely that in the Swiss population of about 3.5 million households at least
a few people are watching even exotic programs at exotic times of the day. 
However, out of a panel of 2000 households chances are high that no one was 
watching that content. This is not a bias of the measurement but poor resolution.

A solution to this problem could be the inclusion of third party data. 
Set-Top-Boxes (STB) of TV-provider (Swisscom, UPC, etc.) are automatically 
recording the TV consumption in millions of Swiss homes and the data is returned
to the providers servers (return path data, RPD). There are still many issues 
with these data that are currently addressed. 

One major issue of RPD is that the viewing data is on household level, not on 
individual level. Household-level data is of little use to the market. Because it
gives no insight in target groups based on age and gender and alike. 

It is unlikely that RPD provider will ever measure the individual viewing or 
survey individual demographics within the subscribers homes. Apart from region 
code, the only information about the home is the viewing data itself. So the 
question arises if it is possible to predict the household composition based 
on viewing behavior.

The aim of this study is to explore the possibility to predict the household 
composition within a household using TV viewing data. It seems to be a 
two-step-problem, first to find the number of household members and then to 
assign age and gender to the individuals.

We will use the _Mediapulse TV-Panel_ and its viewing data to study the subject.
For all households in the panel its composition including household size and 
age and sex of each person is known. For each panel home the viewing 
data will be aggregated to household level. Different supervised machine 
learning algorithms will be fed with features extracted from that household 
viewing data.

# Target and Feauture

## Target: Household Composition

In this study, the aim is to predict the household composition in form of the 
household size, e.g. the number of people living in the household. With 4388 
individuals and 2006 households on our sample day the average household size is
2.19.

The variable _hhsize_ is given in the demographics file of the TV raw-data.
_hhsize_ is not necessarily equal to the sum of individuals for the following 
reasons:

* children 0-2 years old are not part of the panel
* guests are part of the data but not counted for household size
* household size is counted 1, 2, ..., 5+, with 5+ meaning households with 5 or 
more members

Another detail is that household size is not necessarily constant over time. The 
number of people living in a household can change by natural reasons like birth,
death, moving in or out. This fact is neglected here, we assume household size is 
constant over the 8 weeks period we are looking at.

```{r, echo = FALSE, warning = FALSE, messages = FALSE}
library(knitr)
load('~/git/diploma/data/data_predictors.RData')
hh.composition <- as.data.frame(hh.composition)
predictors <- as.data.frame(predictors)
kable(tail(hh.composition[, c(1,3:8,12:16)], 3), row.names = NA, 
      caption="Household composition is the sociodemografic profile of a household, for example, household size, and age and gender of the householdmembers. The last 3 of our sample of 2006 households are shown. For this study the target to predict is _hhsize_.")
```

## Generating Features of Viewing Behavior

### TV Viewing Data

TV viewing data comes in the form of daily text files. There are three types of 
files:

1. `dem`: all individuals with their demographics and daily weights
2. `view`: the TV viewing (live and time-shifted viewing)
3. `prog`: the program timetable with genre information

A commercial software allows Mediapulse and its clients to analyse this data 
via an easy to use software tool. I have written an R-package that allows to read and 
analyse the very same input raw-data and output the very same results (e.g. 
daily estimates the so called "Facts" like _Reach_, _Rating_ or _Share_, etc.). 
Because the results between Software and R-package match, I am not only sure 
that the data processing in R is correct but also understand exactly the calculations being used.

```{r, tab1, echo = FALSE}
view <- data.frame(
  day   = rep('2018-01-01', 3),
  hh    = rep(2381, 3),
  ind   = c(1,1,2),
  chn   = c('SRF 1','ARTE','ARTE'),
  start = c('18:04:21', '18:45:20','18:45:20'),
  end   = c('18:13:02', '20:05:45','19:45:03')
)
kable(view, caption="\\label{tab:tab1}TV viewing raw-data (simplified). Reading example: On day `2018-01-01`, in household `2381` individuum `1` is watching channel `SRF 1` from `18:04:21` to `18:13:02`. Later that day this person switches to channel `ARTE` and is joined by another householdmember individuum `2`.")
```

Demographic information is simply joined on keys `day`, `hh` and `ind`. Program schedule is 
joined via an overlap join on keys `day`, `channel` and `start`/`end`. If a viewing statement overlaps with multiple programs, the statement gets duplicated and the 
`start`/`end` intervals needs to be cropped to the viewing interval boundaries.

### Selecting 8 Weeks of Viewing Data

For this study, a sample day was fixed, and the viewing data of all panel member
present at that day is collected 4 weeks prior and 4 weeks after that date. 
The sample day is the Sunday `2017-11-12` and comprises 2006 households and 4388 individuals respectively. 

The period of eight weeks should be long enough to reflect individual viewing 
behavior. Autumn was chosen because during colder months people are watching 
more TV than in Summer. Also this period is free of holidays or unusual TV events
(FIFA Worldcup, etc.). Within the eight weeks all seven weekdays are equally 
frequent. This is important as TV viewing differs significantly between weekends 
and workdays (Figure \ref{fig:fig1}).

### TV Viewing on Household Level

The TV raw-data described earlier shows that _Mediapulse TV data_ is recorded for
each individual. With RPD data however this is not the case. RPD data only provide 
viewing data on household level. Which person, or how many person are sitting in
front of the TV set is unknown. Also, there is no demographic information 
accompanying RPD data. Here we study if it is possible to predict at least the 
number of household members if only TV viewing on household level is known, like 
with RPD data. To this end the _Mediapulse TV data_ have to be aggregated form 
individual level to household level. This means, if more than one person is 
watching the same content, on household level, this is reflected by a single 
viewing statement. This household aggregation algorithm is somewhat more complex, 
but not further discussed here.

### Feature Generation

Features are a set of variables that are used as input data for Machine Learning 
Classifiers or as predictors for statistical models. In both cases we aim to 
predict the target variable _hhsize_.
To create features of viewing behavior the TV data on household level is summed 
up for each household and day, by different characteristics. Then, for each 
household the average across the 8 weeks was calculated. TV viewing is expressed
as the duration of viewing in seconds. 

The characteristics underlying the feature generation is guided by industry 
knowledge and intuition about TV viewing behavior we believe would carry 
information about the household composition, i.e:

1. Dimension time
    + weekend vs. working days
    + time of the day
    
2. Dimension content
    + type of channel 
    + type of program genre

Figure \ref{fig:fig1}, and Figure \ref{fig:fig2} in the Appendix are illustrating
the effect of the dimension _time_ on total TV viewing. 

There are over 300 TV channels received in Switzerland. In comparison to other 
countries this so called _inspill_ is very large. Because of the small size of 
Switzerland and its different linguistic regions there are many foreign channels 
being watched from the neighboring countries. For simplification the channels 
have been mapped to channel groups. There are 3 type of groups: channel type, 
language, and country of origin.

The program genre is a pre-specified variable in the program schedule files. 
Each program is categorized to one of the 14 different genres. The TV viewing 
data is overlapped and split up by the program schedule. The viewing duration is 
than summed up by each program genre within each household.

```{r, tab3, echo = FALSE}
n <- names(predictors)
t1 <- grep('weekend', n, value = TRUE)
t2 <- grep('workday', n, value = TRUE)
ch <- grep('chn', n, value = TRUE)
pg <- grep('prg', n, value = TRUE)

df <- as.data.frame(matrix(NA, nrow = length(ch), ncol = 3))
names(df) <- c('weekpart by time of day', 'channels', 'programs')
df[1:length(c(t1,t2)), 1] <- c(t1,t2)
#df[1:length(t2), 2] <- t2
df[1:length(ch), 2] <- ch
df[1:length(pg), 3] <- pg

df[is.na(df)] <- ''
kable(df, caption="The sets of features of TV viewing beahvior to predict household composition.")
```

```{r, tab4, echo = FALSE}

if(all(hh.composition$hh == predictors$hh))
  predictors <- cbind(
    hh = predictors[,1], hhsize = hh.composition$hhsize, predictors[,-1]
    )

kable(predictors[1:6, 1:5], caption="Final input data set. Shown are the first 6 rows and the first 5 columns. Earch of the 2006 households is an observation on rows and identified by the household ID _hh_. The householdsize, the taret to predict, is given in column _hhsize_. All 53 above mentioned features are given in the following columns. The values are the average daily viewing duration in seconds by feature on  household level.")
```

# Data Exploration

## Classification versus Regression

Theoretically household size can be interpret both as five separate categories 
or as a scale (ordinal or proportional) ranging from 1 to 5. For this study we interpret household size as categorical variable and therefor apply classification not regression. One reason is that behind a specific household size very different
types of household compositions may exist. For example a two person household could consist of an elderly couple, a two young students of the same gender, a single parent with a child, etc. Accordingly the TV viewing behavior in households of the same size
may differ significantly given the possible variety of demographics profiles. 

```{r, echo = FALSE}
predictors$hhsize <- factor(predictors$hhsize)
levels(predictors$hhsize) <- paste0("hhsize", levels(predictors$hhsize))
```

## Log Transformation

Screening through the values of the 53 feature variables reveals that often the
viewing duration is strongly right skewed and zero inflated (see Figure \ref{fig:fig3} in the Appendix). That means most households have a relatively low value of TV viewing duration but for a few households the viewing is relatively high. A log transformation makes the data more symmetric. Although in general for Machine Learning algorithms such a transformation is unnecessary, it should neither be harmful, and we continue with log transformed data. Because of many zero values we use the transformation 'log(x + 1)'.

```{r, echo = FALSE}
pred.log <- cbind(predictors[, (1:2)], lapply(predictors[, -(1:2)] + 1, log))
```

## Visualisation of Features

Before applying statistcal methods, we can simply visually explore if there is a predictor variable that separates well the households by housholdsize. Figure \ref{fig:fig4} in the Appendix shows some examples. For most features there is
no such discrimination power apparent. But the amount of viewing kinds channels 
seems to separate small and bigger households.

## Dimensionality Reduction

The 53 features are not a lot. Still, some of these variables may not carry much information or they are redundant to other variables (e.g. highly corellated). 
For an example of Dimensionality Reduction Principal Component Analysis (PCA) 
was chosen. PCA was calculated using the 'prcomp' package with centering but no scaling of the log transformed data matrix. All the features represent the same 
unit of viewing duration. Figure \ref{fig:fig5} in the Appendix shows the results
of the PCA.

```{r, tab5, echo = FALSE}

pca <- prcomp(pred.log[,-(1:2)], center = TRUE, scale. = TRUE)

x <- t(summary(pca)$importance[, 1:6])
kable(x, caption="\\label{tab:tab5} First 6 PCs. The Variance in the feature marix is not easily seperated in orthogonal components. To reach 80% cumulativey explained variance the first 16 PCs would be needed.")
```

## Probability to Correctly Classify by Chance

The probability to correctly classify by chance is 20%, if all five categories 
of household size were uniformly distributed (naive estimation). 

```{r, echo = TRUE}
x <- replicate(100, sample(1:5, nrow(hh.composition), replace = TRUE))
round(mean(apply(x, 2, function(y) mean(y == hh.composition$hhsize))), 2)
```

However, we know the probability of each household size category in our sample:

```{r, echo = TRUE}
p <- prop.table(table(hh.composition$hhsize))
c(hhsize = round(p*100, 2))
```

Therefore we can calculate the probability of correct classification by chance
more precisely:

```{r, echo = TRUE}
round(sum(p^2), 2)
```

The estimation by simulation comes close:

```{r, echo = TRUE}
x <- replicate(100, sample(1:5, nrow(hh.composition), replace = TRUE, prob = p))
round(mean(apply(x, 2, function(y) mean(y == hh.composition$hhsize))), 2)
```


## Partitioning into Train and Test Datasets

The 2006 households are split into two datasets, one for training and one for 
testing. The training data makes 60% of households and will be used to train the different models. The test data consists of the other 40% of households and will 
be used to test how good the trained models perform on classifying new data.

```{r, echo = TRUE, message = FALSE}
library(caret)
set.seed(999)
train <- caret::createDataPartition(pred.log$hhsize, p = .6, list = FALSE)
d <- list(train = pred.log[train,-1], test = pred.log[-train,-1])
```

A stratified random sampling is used to split the households. Stratification by 
household size guarantees that the ration of each household size category is 
equal between train and test data. 

```{r, tab6, echo = FALSE}
x <- cbind(`train n` = table(d$train$hhsize), `test n` = table(d$test$hhsize))
x <- cbind(x, cbind(`train %` = x[,1]/sum(x[,1]), `test %` = x[,2]/sum(x[,2])))
kable(round(x, 2), caption="\\label{tab:tab6} The 2006 household are split randomly into train (60%) and test (40%) data, with stratification by household size.")
```

# Model Specification

## Multinomial Linear Model

```{r, echo = TRUE, results = 'hide'}
library(nnet)
m.mnr <- multinom(hhsize ~ ., data = d$train, trace = TRUE, maxit = 500)
```

## Support Vector Machine

```{r, echo = TRUE, message = FALSE}
library(e1071)
m.svm.linear <- svm(hhsize ~ ., data = d$train, kernel = "linear", cost = 1)
m.svm.radial <- svm(hhsize ~ ., data = d$train, kernel = "radial", cost = 15, 
                    gamma = 0.01)
```

## Random Forest

```{r, echo = TRUE, message = FALSE}
library(randomForest)
m.rf <- randomForest(hhsize ~ ., data = d$train, imortance = TRUE, 
                     strata = d$train$hhsize, 
                     sampsize = rep(min(table(d$train$hhsize)), 5))
```

# Performance

## Accuracy

```{r, echo = TRUE}
models <- list(
  multinomial  = m.mnr, 
  randomforest = m.rf, 
  svm.linear   = m.svm.linear,
  svm.radial   = m.svm.radial
  )

pred <- list(
  train = as.data.frame(lapply(models, predict)),
  test  = as.data.frame(lapply(models, predict, newdata = d$test))
)

calc.acc <- function(predicted, observed) mean(predicted == observed)

tabl.acc <- rbind(
  train = sapply(pred$train, calc.acc, observed = d$train$hhsize),
  test  = sapply(pred$test,  calc.acc, observed = d$test$hhsize)
)
```

```{r, tab7, echo = FALSE}
kable(round(t(tabl.acc), 2), caption="\\label{tab:tab7} The Accuracy in train and test dataset for the different classifiers.")
```

## Cohen's Kappa

```{r, echo = TRUE, message = FALSE}
library(psych)
calc.kappa <- function(predicted, observed, param) {
  mx <- table(observed = observed, predicted = predicted)
  cohen.kappa(mx)[[param]]
}

tabl.kappa <- rbind(
  train = sapply(pred$train, calc.kappa, observed = d$train$hhsize, 'weighted.kappa'),
  test  = sapply(pred$test,  calc.kappa, observed = d$test$hhsize, 'weighted.kappa')
)
```

```{r, tab8, echo = FALSE}
kable(round(t(tabl.kappa), 2), caption="\\label{tab:tab8} Cohren's weighted Kappa in train and test dataset for the different classifiers.")
```

## Confusion Matrix

Cohen's kappa takes into account the the probability of chance of each category.
It is somewhat more 

Cohen's weighted kappa punishes disagreement more as further appart the categories lie. For example, incorrectly classifying a household of size 1 as 5 is worse than 2.
Using weighted kappa is somwhat contradicting to our earlier statement to interpret
household size not as an ordered scale.

```{r, echo = TRUE, message = FALSE}
agree <- list(
  train = lapply(pred$train, calc.kappa, observed = d$train$hhsize, 'agree'),
  test  = lapply(pred$test,  calc.kappa, observed = d$test$hhsize, 'agree')
)
agree <- do.call(rbind, lapply(agree$test, as.data.frame))
agree$model <- sub('\\.\\d+', '', rownames(agree))
names(agree)[3] <- 'agreement'
```

```{r, fig7, echo = FALSE, message = FALSE, fig.pos="H", fig.cap="\\label{fig:fig7} Heatmaps of Cohen's agreement matrix for each model"}
library(ggplot2)
ggplot(agree, aes(observed, predicted, agreement)) + 
  geom_tile(aes(fill = agreement)) + theme_bw() + facet_grid( ~ model)
```



# Discussion


# Appendix

```{r, fig1, echo = FALSE, fig.pos="H", out.width="75%", fig.align="center", fig.cap="\\label{fig:fig1}The sum of TV viewing duration [seconds] by weekdays during 2017. On weekends more TV is watched than during the rest of the week. Festival days often behave like Sundays."}

suppressWarnings(library(knitr))
include_graphics('../data/tv-week.png')

```

```{r fig2, echo = FALSE, fig.pos="H", out.width="75%", fig.align="center", fig.cap="\\label{fig:fig2} The relative amount of TV viewing across time of the day. The curve is the average of all 365 days in 2017. In the market the peak around 20:00 o'clock is called Primetime. On weekends the curve is flatter."}

include_graphics('../data/tv-day.png')

```

```{r, fig3, echo = FALSE, fig.pos="H", fig.cap="\\label{fig:fig3} Illustration of log transformation. The upper row of scatterplots shows three examples of feature pairs. On of for each domain _time_, _channel_ and _program_. In many cases viewing duration is not symmetrical distributed. The lower row shows the very same scatterplot with log transformed values."}

vars <- list(
  time    = c('day_weekend_17to20','day_workday_17to20'),
  channel = c('chn_arts','chn_kids'),
  program = c('prg_sport','prg_news')
  )
par(mfrow = c(2,3))
plot(predictors[, vars$time])
plot(predictors[, vars$channel], main = 'viewing in seconds')
plot(predictors[, vars$program])
plot(pred.log[, vars$time])
plot(pred.log[, vars$channel], main = 'log of viewing in seconds')
plot(pred.log[, vars$program])

```

```{r, fig4, echo = FALSE, fig.pos="H", fig.cap="\\label{fig:fig4} Shown are the same three scatterplots as in the Figure above but this time the corresponding household size is indicated by the color of the dots. If there was a feature that would separate the households (dots) into clusters of the same color, this would tell us that this particular variable is a good discriminator for household size. Apprently the variable _chn_kids_ separates black and red dots from light and dark blue dots. This means there is a tendency that the more a household watches TV on typical kids channels, the more likely it is a 4 or 5 person household."}

fun <- function(x, main = NULL, col = adjustcolor(as.integer(pred.log$hhsize), .65))
  plot(x, main = main, bg = col, pch = 21, cex = 1, col = col, frame.plot = FALSE)
  
par(mfcol = c(1,3))
fun(pred.log[, vars$time])
legend('topleft', paste('hhsize', 1:5), pch = 21, bty = 'n', 
       pt.bg = adjustcolor(1:5, .65), col = adjustcolor(1:5, .65))
fun(pred.log[, vars$channel], main = 'Clusters of hhsize')
fun(pred.log[, vars$program])

```

```{r, fig5, echo = FALSE, fig.pos="H", out.width="50%", fig.align="center", fig.cap="\\label{fig:fig4} Principal Component Analysis (PCA). Above the Screeplots shows the variance explained by the first 10 of principal components (PCs). The first PC explaine 30% of the total variance. Below, scatterplots and biplots of the first 3 PCs."}

par(mfcol = c(1,1))
plot(pca)
```

```{r, echo = FALSE, fig.pos="H"}

par(mfrow = c(2,3))
# layout(matrix(c(0,1,0,2,3,4), 2, byrow = TRUE))
fun(pca$x[, c(1,2)])
fun(pca$x[, c(1,3)])
fun(pca$x[, c(2,3)])
legend('topright', paste('hhsize', 1:5), pch = 21, bty = 'n', 
       pt.bg = adjustcolor(1:5, .65), col = adjustcolor(1:5, .65))

biplot(pca, choices = c(1,2))
biplot(pca, choices = c(1,3))
biplot(pca, choices = c(2,3))
```